#!/usr/bin/env python3
"""
Stable Video Diffusion è§†é¢‘ç”Ÿæˆæ¨¡å‹æµ‹è¯•ç¨‹åº
"""

import os
import torch
from PIL import Image
from datetime import datetime
import numpy as np

def test_stable_video_diffusion():
    """æµ‹è¯• Stable Video Diffusion æ¨¡å‹"""
    print("ğŸ¬ æµ‹è¯• Stable Video Diffusion è§†é¢‘ç”Ÿæˆæ¨¡å‹")
    print("=" * 50)
    
    try:
        # æ£€æŸ¥CUDAå¯ç”¨æ€§
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
        
        # å¯¼å…¥æ¨¡å‹
        from diffusers import StableVideoDiffusionPipeline
        
        print("ğŸ”„ æ­£åœ¨åŠ è½½ Stable Video Diffusion æ¨¡å‹...")
        pipeline = StableVideoDiffusionPipeline.from_pretrained(
            "stabilityai/stable-video-diffusion-img2vid-xt",
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            variant="fp16" if device == "cuda" else None
        )
        
        if device == "cuda":
            pipeline = pipeline.to("cuda")
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "data/test_outputs/svd"
        os.makedirs(output_dir, exist_ok=True)
        
        # å‡†å¤‡æµ‹è¯•å›¾åƒ
        test_images = []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰çš„æµ‹è¯•å›¾åƒ
        test_image_paths = [
            "data/scenes/scene_001.png",
            "data/scenes/123.jpg"
        ]
        
        for img_path in test_image_paths:
            if os.path.exists(img_path):
                try:
                    img = Image.open(img_path).convert("RGB")
                    # è°ƒæ•´å›¾åƒå°ºå¯¸åˆ°æ¨¡å‹è¦æ±‚
                    img = img.resize((1024, 576))  # SVDæ¨èå°ºå¯¸
                    test_images.append((img, os.path.basename(img_path)))
                    print(f"ğŸ“¸ åŠ è½½æµ‹è¯•å›¾åƒ: {img_path}")
                except Exception as e:
                    print(f"âš ï¸ æ— æ³•åŠ è½½å›¾åƒ {img_path}: {e}")
        
        # å¦‚æœæ²¡æœ‰ç°æœ‰å›¾åƒï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾åƒ
        if not test_images:
            print("ğŸ“¸ åˆ›å»ºé»˜è®¤æµ‹è¯•å›¾åƒ...")
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¸å˜å›¾åƒ
            img_array = np.zeros((576, 1024, 3), dtype=np.uint8)
            for i in range(576):
                img_array[i, :, 0] = int(255 * i / 576)  # çº¢è‰²æ¸å˜
                img_array[i, :, 1] = int(128)  # ç»¿è‰²å›ºå®š
                img_array[i, :, 2] = int(255 * (576 - i) / 576)  # è“è‰²åå‘æ¸å˜
            
            test_img = Image.fromarray(img_array)
            test_images.append((test_img, "gradient_test.png"))
        
        # ç”Ÿæˆè§†é¢‘
        for i, (image, img_name) in enumerate(test_images):
            print(f"\nğŸ¯ æµ‹è¯• {i+1}/{len(test_images)}: {img_name}")
            
            try:
                # ç”Ÿæˆè§†é¢‘å¸§
                print("ğŸ”„ æ­£åœ¨ç”Ÿæˆè§†é¢‘å¸§...")
                with torch.no_grad():
                    frames = pipeline(
                        image=image,
                        num_frames=14,  # SVDé»˜è®¤å¸§æ•°
                        num_inference_steps=25,
                        fps=7,
                        motion_bucket_id=127,  # è¿åŠ¨å¼ºåº¦
                        noise_aug_strength=0.02
                    ).frames[0]
                
                # ä¿å­˜è§†é¢‘å¸§
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                frame_dir = os.path.join(output_dir, f"svd_test_{i+1}_{timestamp}")
                os.makedirs(frame_dir, exist_ok=True)
                
                for j, frame in enumerate(frames):
                    frame_path = os.path.join(frame_dir, f"frame_{j:03d}.png")
                    frame.save(frame_path)
                
                print(f"âœ… è§†é¢‘å¸§ç”ŸæˆæˆåŠŸ: {frame_dir}")
                print(f"   å¸§æ•°: {len(frames)}")
                print(f"   åˆ†è¾¨ç‡: {frames[0].size}")
                
                # å°è¯•åˆæˆä¸ºè§†é¢‘æ–‡ä»¶
                try:
                    video_path = create_video_from_frames(frame_dir, f"svd_test_{i+1}_{timestamp}.mp4")
                    if video_path:
                        print(f"ğŸ¬ è§†é¢‘æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {video_path}")
                except Exception as e:
                    print(f"âš ï¸ è§†é¢‘åˆæˆå¤±è´¥: {e}")
                    print("   å¸§åºåˆ—å·²ä¿å­˜ï¼Œå¯æ‰‹åŠ¨åˆæˆè§†é¢‘")
                
            except Exception as e:
                print(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
        
        print(f"\nğŸ‰ Stable Video Diffusion æµ‹è¯•å®Œæˆ")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·å®‰è£…å¿…è¦çš„ä¾èµ–: pip install diffusers torch")
        return False
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def create_video_from_frames(frame_dir, output_name):
    """ä»å¸§åºåˆ—åˆ›å»ºè§†é¢‘æ–‡ä»¶"""
    try:
        import cv2
        
        # è·å–å¸§æ–‡ä»¶åˆ—è¡¨
        frame_files = sorted([f for f in os.listdir(frame_dir) if f.endswith('.png')])
        if not frame_files:
            return None
        
        # è¯»å–ç¬¬ä¸€å¸§è·å–å°ºå¯¸
        first_frame_path = os.path.join(frame_dir, frame_files[0])
        first_frame = cv2.imread(first_frame_path)
        height, width, _ = first_frame.shape
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        output_path = os.path.join(frame_dir, output_name)
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        video_writer = cv2.VideoWriter(output_path, fourcc, 7.0, (width, height))
        
        # å†™å…¥æ‰€æœ‰å¸§
        for frame_file in frame_files:
            frame_path = os.path.join(frame_dir, frame_file)
            frame = cv2.imread(frame_path)
            video_writer.write(frame)
        
        video_writer.release()
        return output_path
        
    except ImportError:
        print("âš ï¸ OpenCVæœªå®‰è£…ï¼Œæ— æ³•åˆæˆè§†é¢‘æ–‡ä»¶")
        return None
    except Exception as e:
        print(f"âš ï¸ è§†é¢‘åˆæˆé”™è¯¯: {e}")
        return None

def test_model_info():
    """æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯"""
    print("\nğŸ“‹ Stable Video Diffusion æ¨¡å‹ä¿¡æ¯")
    print("-" * 30)
    print("æ¨¡å‹åç§°: stabilityai/stable-video-diffusion-img2vid-xt")
    print("åŠŸèƒ½: å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆ")
    print("è¾“å…¥åˆ†è¾¨ç‡: 1024x576 (æ¨è)")
    print("è¾“å‡ºå¸§æ•°: 14å¸§ (çº¦2ç§’@7fps)")
    print("æ¨èæ­¥æ•°: 25")
    print("å†…å­˜éœ€æ±‚: 8-12GB VRAM (GPU) / 32GB RAM (CPU)")
    print("è¿åŠ¨å¼ºåº¦: 0-255 (127ä¸ºé»˜è®¤)")

if __name__ == "__main__":
    test_model_info()
    success = test_stable_video_diffusion()
    
    if success:
        print("\nğŸŠ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâš ï¸ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")