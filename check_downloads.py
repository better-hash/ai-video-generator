#!/usr/bin/env python3
"""
æ£€æŸ¥AIæ¨¡å‹ä¸‹è½½çŠ¶æ€
"""

import os
import sys
from pathlib import Path
import json

def check_model_downloads():
    """æ£€æŸ¥æ¨¡å‹ä¸‹è½½çŠ¶æ€"""
    print("ğŸ” æ£€æŸ¥AIæ¨¡å‹ä¸‹è½½çŠ¶æ€")
    print("=" * 50)
    
    # è·å–ç¼“å­˜ç›®å½•
    cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
    
    if not cache_dir.exists():
        print("âŒ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")
        return
    
    print(f"ğŸ“ ç¼“å­˜ç›®å½•: {cache_dir}")
    
    # æ£€æŸ¥å„ä¸ªæ¨¡å‹
    models_to_check = [
        {
            "name": "Stable Video Diffusion",
            "path": "models--stabilityai--stable-video-diffusion-img2vid-xt",
            "expected_files": 9,
            "status": "â“"
        },
        {
            "name": "Stable Diffusion XL", 
            "path": "models--stabilityai--stable-diffusion-xl-base-1.0",
            "expected_files": 19,
            "status": "â“"
        },
        {
            "name": "SpeechT5",
            "path": "models--microsoft--speecht5_tts",
            "expected_files": 5,
            "status": "â“"
        }
    ]
    
    total_size = 0
    all_complete = True
    
    for model in models_to_check:
        model_path = cache_dir / model["path"]
        
        if model_path.exists():
            # è®¡ç®—æ–‡ä»¶å¤§å°
            size = sum(f.stat().st_size for f in model_path.rglob('*') if f.is_file())
            total_size += size
            
            # æ£€æŸ¥æ–‡ä»¶æ•°é‡
            files = list(model_path.rglob('*'))
            file_count = len([f for f in files if f.is_file()])
            
            if file_count >= model["expected_files"]:
                model["status"] = "âœ…"
                print(f"{model['status']} {model['name']}")
                print(f"   æ–‡ä»¶æ•°: {file_count}/{model['expected_files']}")
                print(f"   å¤§å°: {size / (1024**3):.2f} GB")
            else:
                model["status"] = "âš ï¸"
                all_complete = False
                print(f"{model['status']} {model['name']} (éƒ¨åˆ†ä¸‹è½½)")
                print(f"   æ–‡ä»¶æ•°: {file_count}/{model['expected_files']}")
                print(f"   å¤§å°: {size / (1024**3):.2f} GB")
        else:
            model["status"] = "âŒ"
            all_complete = False
            print(f"{model['status']} {model['name']} (æœªä¸‹è½½)")
    
    print(f"\nğŸ“Š æ€»ç»“:")
    print(f"   æ€»å¤§å°: {total_size / (1024**3):.2f} GB")
    print(f"   çŠ¶æ€: {'âœ… å…¨éƒ¨å®Œæˆ' if all_complete else 'âš ï¸ éƒ¨åˆ†å®Œæˆ'}")
    
    return all_complete

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åº“"""
    print("\nğŸ”§ æ£€æŸ¥ä¾èµ–åº“")
    print("=" * 30)
    
    dependencies = [
        ("torch", "PyTorch"),
        ("diffusers", "Diffusers"),
        ("transformers", "Transformers"),
        ("sentencepiece", "SentencePiece"),
        ("cv2", "OpenCV"),
        ("PIL", "Pillow")
    ]
    
    missing_deps = []
    
    for module, name in dependencies:
        try:
            __import__(module)
            print(f"âœ… {name}")
        except ImportError:
            print(f"âŒ {name} (ç¼ºå¤±)")
            missing_deps.append(module)
    
    if missing_deps:
        print(f"\nâš ï¸ ç¼ºå¤±ä¾èµ–: {', '.join(missing_deps)}")
        print("å®‰è£…å‘½ä»¤:")
        for dep in missing_deps:
            print(f"   pip install {dep}")
    
    return len(missing_deps) == 0

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹åŠ è½½")
    print("=" * 30)
    
    try:
        import torch
        
        # æµ‹è¯•å›¾åƒç”Ÿæˆæ¨¡å‹
        print("æµ‹è¯• Stable Diffusion XL...")
        from diffusers import StableDiffusionPipeline
        pipeline = StableDiffusionPipeline.from_pretrained(
            "stabilityai/stable-diffusion-xl-base-1.0",
            torch_dtype=torch.float16,
            safety_checker=None
        )
        print("âœ… Stable Diffusion XL åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•è§†é¢‘ç”Ÿæˆæ¨¡å‹
        print("æµ‹è¯• Stable Video Diffusion...")
        from diffusers import StableVideoDiffusionPipeline
        svd_pipeline = StableVideoDiffusionPipeline.from_pretrained(
            "stabilityai/stable-video-diffusion-img2vid-xt",
            torch_dtype=torch.float16,
            variant="fp16"
        )
        print("âœ… Stable Video Diffusion åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•è¯­éŸ³åˆæˆæ¨¡å‹
        print("æµ‹è¯• SpeechT5...")
        from transformers import pipeline
        tts_pipeline = pipeline("text-to-speech", model="microsoft/speecht5_tts")
        print("âœ… SpeechT5 åŠ è½½æˆåŠŸ")
        
        print("\nğŸ‰ æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” AIæ¨¡å‹ä¸‹è½½çŠ¶æ€æ£€æŸ¥")
    print("=" * 60)
    
    # æ£€æŸ¥ä¸‹è½½çŠ¶æ€
    downloads_ok = check_model_downloads()
    
    # æ£€æŸ¥ä¾èµ–
    deps_ok = check_dependencies()
    
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    if downloads_ok and deps_ok:
        print("\nğŸš€ å°è¯•åŠ è½½æ¨¡å‹...")
        models_ok = test_model_loading()
    else:
        models_ok = False
    
    # æ€»ç»“
    print(f"\nğŸ“‹ æ£€æŸ¥ç»“æœ:")
    print(f"   ä¸‹è½½çŠ¶æ€: {'âœ… å®Œæˆ' if downloads_ok else 'âŒ ä¸å®Œæ•´'}")
    print(f"   ä¾èµ–çŠ¶æ€: {'âœ… å®Œæ•´' if deps_ok else 'âŒ ç¼ºå¤±'}")
    print(f"   æ¨¡å‹åŠ è½½: {'âœ… æˆåŠŸ' if models_ok else 'âŒ å¤±è´¥'}")
    
    if downloads_ok and deps_ok and models_ok:
        print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥æ­£å¸¸ä½¿ç”¨AIåŠŸèƒ½ã€‚")
    else:
        print("\nâš ï¸ éœ€è¦ä¿®å¤ä¸€äº›é—®é¢˜æ‰èƒ½æ­£å¸¸ä½¿ç”¨AIåŠŸèƒ½ã€‚")
        print("å»ºè®®ä½¿ç”¨ç®€åŒ–æ¨¡å¼è¿›è¡Œæµ‹è¯•ã€‚")

if __name__ == "__main__":
    main() 