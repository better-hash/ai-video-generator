#!/usr/bin/env python3
"""
SpeechT5 è¯­éŸ³åˆæˆæ¨¡å‹æµ‹è¯•ç¨‹åº
"""

import os
import torch
from datetime import datetime
import numpy as np

def test_speecht5_tts():
    """æµ‹è¯• SpeechT5 è¯­éŸ³åˆæˆæ¨¡å‹"""
    print("ğŸ¤ æµ‹è¯• SpeechT5 è¯­éŸ³åˆæˆæ¨¡å‹")
    print("=" * 50)
    
    try:
        # æ£€æŸ¥CUDAå¯ç”¨æ€§
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
        
        # å¯¼å…¥æ¨¡å‹
        from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan
        
        print("ğŸ”„ æ­£åœ¨åŠ è½½ SpeechT5 æ¨¡å‹...")
        
        # åŠ è½½å¤„ç†å™¨
        processor = SpeechT5Processor.from_pretrained("microsoft/speecht5_tts")
        print("âœ… å¤„ç†å™¨åŠ è½½æˆåŠŸ")
        
        # åŠ è½½æ–‡æœ¬è½¬è¯­éŸ³æ¨¡å‹
        model = SpeechT5ForTextToSpeech.from_pretrained("microsoft/speecht5_tts")
        print("âœ… TTSæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # åŠ è½½å£°ç å™¨
        vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")
        print("âœ… å£°ç å™¨åŠ è½½æˆåŠŸ")
        
        # ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡
        if device == "cuda":
            model = model.to("cuda")
            vocoder = vocoder.to("cuda")
            print("âœ… æ¨¡å‹å·²ç§»åŠ¨åˆ°GPU")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "data/test_outputs/tts"
        os.makedirs(output_dir, exist_ok=True)
        
        # æµ‹è¯•æ–‡æœ¬
        test_texts = [
            "Hello, this is a test of the SpeechT5 text-to-speech model.",
            "The weather is beautiful today, perfect for a walk in the park.",
            "Artificial intelligence is transforming the way we work and live.",
            "Thank you for testing the speech synthesis system."
        ]
        
        # åˆ›å»ºé»˜è®¤è¯´è¯äººåµŒå…¥
        print("ğŸ”„ åˆ›å»ºè¯´è¯äººåµŒå…¥...")
        speaker_embedding = torch.zeros(512)
        if device == "cuda":
            speaker_embedding = speaker_embedding.to("cuda")
        
        # ç”Ÿæˆè¯­éŸ³
        for i, text in enumerate(test_texts):
            print(f"\nğŸ¯ æµ‹è¯• {i+1}/{len(test_texts)}: {text[:50]}...")
            
            try:
                # é™åˆ¶æ–‡æœ¬é•¿åº¦
                text = text[:200] if len(text) > 200 else text
                
                # å¤„ç†è¾“å…¥æ–‡æœ¬
                inputs = processor(text=text, return_tensors="pt")
                
                # ç§»åŠ¨è¾“å…¥åˆ°è®¾å¤‡
                if device == "cuda":
                    inputs = {k: v.to("cuda") for k, v in inputs.items()}
                
                # ç”Ÿæˆè¯­éŸ³
                print("ğŸ”„ æ­£åœ¨ç”Ÿæˆè¯­éŸ³...")
                with torch.no_grad():
                    speech = model.generate_speech(
                        inputs["input_ids"], 
                        speaker_embedding.unsqueeze(0), 
                        vocoder=vocoder
                    )
                
                # ä¿å­˜è¯­éŸ³æ–‡ä»¶
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"tts_test_{i+1}_{timestamp}.wav"
                filepath = os.path.join(output_dir, filename)
                
                # ä½¿ç”¨soundfileä¿å­˜
                try:
                    import soundfile as sf
                    sf.write(filepath, speech.cpu().numpy(), 16000)
                    print(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ: {filepath}")
                    print(f"   é‡‡æ ·ç‡: 16000 Hz")
                    print(f"   æ—¶é•¿: {len(speech.cpu().numpy()) / 16000:.2f} ç§’")
                except ImportError:
                    # å¦‚æœæ²¡æœ‰soundfileï¼Œä½¿ç”¨scipy
                    try:
                        from scipy.io import wavfile
                        wavfile.write(filepath, 16000, speech.cpu().numpy())
                        print(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ: {filepath}")
                        print(f"   é‡‡æ ·ç‡: 16000 Hz")
                        print(f"   æ—¶é•¿: {len(speech.cpu().numpy()) / 16000:.2f} ç§’")
                    except ImportError:
                        print("âŒ æ— æ³•ä¿å­˜éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·å®‰è£… soundfile æˆ– scipy")
                        # è‡³å°‘ä¿å­˜ä¸ºnumpyæ•°ç»„
                        np_filepath = filepath.replace('.wav', '.npy')
                        np.save(np_filepath, speech.cpu().numpy())
                        print(f"âœ… è¯­éŸ³æ•°æ®ä¿å­˜ä¸ºnumpyæ•°ç»„: {np_filepath}")
                
            except Exception as e:
                print(f"âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
        
        # æµ‹è¯•ä¸­æ–‡æ–‡æœ¬ï¼ˆå¦‚æœæ”¯æŒï¼‰
        print("\nğŸŒ æµ‹è¯•ä¸­æ–‡è¯­éŸ³åˆæˆ...")
        chinese_texts = [
            "ä½ å¥½ï¼Œè¿™æ˜¯è¯­éŸ³åˆæˆæµ‹è¯•ã€‚",
            "ä»Šå¤©å¤©æ°”å¾ˆå¥½ã€‚"
        ]
        
        for i, text in enumerate(chinese_texts):
            try:
                print(f"ğŸ¯ ä¸­æ–‡æµ‹è¯• {i+1}: {text}")
                
                # å¤„ç†ä¸­æ–‡æ–‡æœ¬
                inputs = processor(text=text, return_tensors="pt")
                
                if device == "cuda":
                    inputs = {k: v.to("cuda") for k, v in inputs.items()}
                
                with torch.no_grad():
                    speech = model.generate_speech(
                        inputs["input_ids"], 
                        speaker_embedding.unsqueeze(0), 
                        vocoder=vocoder
                    )
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"tts_chinese_{i+1}_{timestamp}.wav"
                filepath = os.path.join(output_dir, filename)
                
                try:
                    import soundfile as sf
                    sf.write(filepath, speech.cpu().numpy(), 16000)
                    print(f"âœ… ä¸­æ–‡è¯­éŸ³ç”ŸæˆæˆåŠŸ: {filepath}")
                except:
                    np_filepath = filepath.replace('.wav', '.npy')
                    np.save(np_filepath, speech.cpu().numpy())
                    print(f"âœ… ä¸­æ–‡è¯­éŸ³æ•°æ®ä¿å­˜: {np_filepath}")
                    
            except Exception as e:
                print(f"âš ï¸ ä¸­æ–‡è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
                print("   SpeechT5ä¸»è¦é’ˆå¯¹è‹±æ–‡ä¼˜åŒ–")
        
        print(f"\nğŸ‰ SpeechT5 æµ‹è¯•å®Œæˆ")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·å®‰è£…å¿…è¦çš„ä¾èµ–: pip install transformers torch soundfile")
        return False
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_speaker_embeddings():
    """æµ‹è¯•ä¸åŒçš„è¯´è¯äººåµŒå…¥"""
    print("\nğŸ­ æµ‹è¯•ä¸åŒè¯´è¯äººåµŒå…¥")
    print("-" * 30)
    
    try:
        from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan
        import torch
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # åŠ è½½æ¨¡å‹
        processor = SpeechT5Processor.from_pretrained("microsoft/speecht5_tts")
        model = SpeechT5ForTextToSpeech.from_pretrained("microsoft/speecht5_tts")
        vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")
        
        if device == "cuda":
            model = model.to("cuda")
            vocoder = vocoder.to("cuda")
        
        # åˆ›å»ºä¸åŒçš„è¯´è¯äººåµŒå…¥
        embeddings = {
            "default": torch.zeros(512),
            "variant1": torch.randn(512) * 0.1,
            "variant2": torch.randn(512) * 0.2
        }
        
        test_text = "This is a test with different speaker embeddings."
        output_dir = "data/test_outputs/tts"
        os.makedirs(output_dir, exist_ok=True)
        
        for name, embedding in embeddings.items():
            try:
                if device == "cuda":
                    embedding = embedding.to("cuda")
                
                inputs = processor(text=test_text, return_tensors="pt")
                if device == "cuda":
                    inputs = {k: v.to("cuda") for k, v in inputs.items()}
                
                with torch.no_grad():
                    speech = model.generate_speech(
                        inputs["input_ids"], 
                        embedding.unsqueeze(0), 
                        vocoder=vocoder
                    )
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"speaker_{name}_{timestamp}.wav"
                filepath = os.path.join(output_dir, filename)
                
                try:
                    import soundfile as sf
                    sf.write(filepath, speech.cpu().numpy(), 16000)
                    print(f"âœ… è¯´è¯äºº {name}: {filepath}")
                except:
                    np_filepath = filepath.replace('.wav', '.npy')
                    np.save(np_filepath, speech.cpu().numpy())
                    print(f"âœ… è¯´è¯äºº {name}: {np_filepath}")
                    
            except Exception as e:
                print(f"âŒ è¯´è¯äºº {name} æµ‹è¯•å¤±è´¥: {e}")
        
    except Exception as e:
        print(f"âŒ è¯´è¯äººåµŒå…¥æµ‹è¯•å¤±è´¥: {e}")

def test_model_info():
    """æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯"""
    print("\nğŸ“‹ SpeechT5 æ¨¡å‹ä¿¡æ¯")
    print("-" * 30)
    print("TTSæ¨¡å‹: microsoft/speecht5_tts")
    print("å£°ç å™¨: microsoft/speecht5_hifigan")
    print("åŠŸèƒ½: æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆ")
    print("é‡‡æ ·ç‡: 16000 Hz")
    print("è¯­è¨€æ”¯æŒ: ä¸»è¦è‹±æ–‡ï¼Œéƒ¨åˆ†å¤šè¯­è¨€")
    print("è¯´è¯äºº: å¯è‡ªå®šä¹‰åµŒå…¥å‘é‡")
    print("å†…å­˜éœ€æ±‚: 2-4GB VRAM (GPU) / 8GB RAM (CPU)")

if __name__ == "__main__":
    test_model_info()
    success = test_speecht5_tts()
    
    if success:
        test_speaker_embeddings()
        print("\nğŸŠ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâš ï¸ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")